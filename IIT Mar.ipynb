{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "my_region = sagemaker_session.boto_session.region_name\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ap-south-1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset through S3 bucket\n",
    "training_data_uri = 'Latest_CV_DATA_HEADER.csv'.format(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latest_CV_DATA_HEADER.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas-profiling\n",
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pd.set_option('display.float_format', lambda x: '%0.3f' % x)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',1000)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/root/PRICE-X/V1/Latest_CV_DATA_HEADER.csv',encoding='latin-1')\n",
    "df_inf = pd.read_csv('/root/PRICE-X/V1/INFLAalpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cwd = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/root/PRICE-X/PriceX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNIQUESERIALNO', 'SOLD_DATE', 'MAKE YEAR', 'Make', 'Model', 'Variant',\n",
       "       'FUEL TYPE_CLEANED', 'mixmmvfuelcleaned', 'BodyType', 'SUBBODYTYPE',\n",
       "       'WHEELS', 'GVW_HP_SEATING_CAPACITY_CC', 'SOLD AMOUNT', 'STATE_MAPPED',\n",
       "       'VEHICLE NO', 'METER READING', 'UCR', 'SHROTCOND_MAPPED', 'INSDT',\n",
       "       'TAX', 'PERMIT_MAPPED', 'SELLERCORPORATENAME', 'SELLERID', 'SELLERNAME',\n",
       "       'KEYREFNUMBER', 'INV_H_RC_STATUS_CLEANED_MAPPED', 'VEHICLECONDITION',\n",
       "       'SELLER SEGMENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year ', 'Price ', 'Inflation rate'], dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf.rename(columns={'Year ':'Year_sell'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401773, 28)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppper(df,col):\n",
    "    df[col]=df[col].str.upper()\n",
    "    df[col]=df[col].str.replace(' ','')\n",
    "    return df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(data,col,col_1,model):\n",
    "    print(model.head())\n",
    "    temp = pd.read_csv(data+'.csv',encoding='CP1252')\n",
    "    temp[col]=uppper(temp,col)\n",
    "    model_temp = pd.DataFrame()\n",
    "    labels_temp_map = dict(zip(temp[col],temp['Id (Encoding)']))\n",
    "    model_temp[col_1] = model[col_1].map(labels_temp_map)\n",
    "    print(model.head())\n",
    "    return model_temp[col_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_reset(df):\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Make':'Make_Clean'},inplace=True)\n",
    "data.rename(columns={'Model':'Model_Clean'},inplace=True)\n",
    "data.rename(columns={'Variant':'Variant_Clean'},inplace=True)\n",
    "data.rename(columns={'GVW_HP_SEATING_CAPACITY_CC':'num_Weight'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNIQUESERIALNO', 'SOLD_DATE', 'MAKE YEAR', 'Make_Clean', 'Model_Clean',\n",
       "       'Variant_Clean', 'FUEL TYPE_CLEANED', 'mixmmvfuelcleaned', 'BodyType',\n",
       "       'SUBBODYTYPE', 'WHEELS', 'num_Weight', 'SOLD AMOUNT', 'STATE_MAPPED',\n",
       "       'VEHICLE NO', 'METER READING', 'UCR', 'SHROTCOND_MAPPED', 'INSDT',\n",
       "       'TAX', 'PERMIT_MAPPED', 'SELLERCORPORATENAME', 'SELLERID', 'SELLERNAME',\n",
       "       'KEYREFNUMBER', 'INV_H_RC_STATUS_CLEANED_MAPPED', 'VEHICLECONDITION',\n",
       "       'SELLER SEGMENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'FUEL TYPE_CLEANED':'Fuel_Clean'},inplace=True)\n",
    "data.rename(columns={'STATE_MAPPED':'CV_State_Clean'},inplace=True)\n",
    "data.rename(columns={'MAKE YEAR':'MAKE_YEAR'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Make_Clean']=uppper(data,'Make_Clean')\n",
    "data['Model_Clean']=uppper(data,'Model_Clean')\n",
    "data['Variant_Clean']=uppper(data,'Variant_Clean')\n",
    "data['Fuel_Clean']=uppper(data,'Fuel_Clean')\n",
    "data['CV_State_Clean']=uppper(data,'CV_State_Clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data.dropna(how='any',axis=0,subset=['Model_Clean','Fuel_Clean','Variant_Clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['MMV']= dt['Make_Clean']+'_'+dt['Model_Clean']+'_'+dt['Variant_Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= dt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401773, 29)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[df_1['SOLD AMOUNT']>48000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364151, 29)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2[df_2['MMV'].map(df_2['MMV'].value_counts()) >=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363909, 29)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 =df_reset(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_reset(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['MAKE_YEAR']>=1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361651, 29)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.CV_State_Clean.fillna(df_1.CV_State_Clean.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.SOLD_DATE=pd.to_datetime(df_1.SOLD_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"Year_sell\"] = df_1.SOLD_DATE.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"Sell_Month\"] = df_1.SOLD_DATE.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"Sell_Day\"] = df_1.SOLD_DATE.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2 = df_1[df_1[\"Year_sell\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"num_CV_Age\"] = df_1[\"Year_sell\"] - df_1['MAKE_YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[df_1[\"num_CV_Age\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343864, 33)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUESERIALNO</th>\n",
       "      <th>SOLD_DATE</th>\n",
       "      <th>MAKE_YEAR</th>\n",
       "      <th>Make_Clean</th>\n",
       "      <th>Model_Clean</th>\n",
       "      <th>Variant_Clean</th>\n",
       "      <th>Fuel_Clean</th>\n",
       "      <th>mixmmvfuelcleaned</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>SUBBODYTYPE</th>\n",
       "      <th>WHEELS</th>\n",
       "      <th>num_Weight</th>\n",
       "      <th>SOLD AMOUNT</th>\n",
       "      <th>CV_State_Clean</th>\n",
       "      <th>VEHICLE NO</th>\n",
       "      <th>METER READING</th>\n",
       "      <th>UCR</th>\n",
       "      <th>SHROTCOND_MAPPED</th>\n",
       "      <th>INSDT</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PERMIT_MAPPED</th>\n",
       "      <th>SELLERCORPORATENAME</th>\n",
       "      <th>SELLERID</th>\n",
       "      <th>SELLERNAME</th>\n",
       "      <th>KEYREFNUMBER</th>\n",
       "      <th>INV_H_RC_STATUS_CLEANED_MAPPED</th>\n",
       "      <th>VEHICLECONDITION</th>\n",
       "      <th>SELLER SEGMENT</th>\n",
       "      <th>MMV</th>\n",
       "      <th>Year_sell</th>\n",
       "      <th>Sell_Month</th>\n",
       "      <th>Sell_Day</th>\n",
       "      <th>num_CV_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S20091800155</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>2013</td>\n",
       "      <td>AMW</td>\n",
       "      <td>2516HL</td>\n",
       "      <td>6X2CARGOTRUCK</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AMW2516HL6X2CARGOTRUCKDIESEL</td>\n",
       "      <td>HAULAGE TRUCK</td>\n",
       "      <td>10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY</td>\n",
       "      <td>10</td>\n",
       "      <td>25000</td>\n",
       "      <td>445000</td>\n",
       "      <td>GUJARAT</td>\n",
       "      <td>GJ16Z6727</td>\n",
       "      <td>490620.000</td>\n",
       "      <td>20%</td>\n",
       "      <td>FAIR</td>\n",
       "      <td>Live : 28/02/2021</td>\n",
       "      <td>Expired : 30/09/2019</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>a9</td>\n",
       "      <td>AP000337591</td>\n",
       "      <td>JAYESHBHAI  ZAVERBHAI PATEL</td>\n",
       "      <td>BHARUO608090001</td>\n",
       "      <td>ORIGINAL RC</td>\n",
       "      <td>MOVABLE</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>AMW_2516HL_6X2CARGOTRUCK</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S21092900303</td>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>2010</td>\n",
       "      <td>AMW</td>\n",
       "      <td>2516HL</td>\n",
       "      <td>6X2CARGOTRUCK</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AMW2516HL6X2CARGOTRUCKDIESEL</td>\n",
       "      <td>HAULAGE TRUCK</td>\n",
       "      <td>10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY</td>\n",
       "      <td>10</td>\n",
       "      <td>25000</td>\n",
       "      <td>315000</td>\n",
       "      <td>TAMILNADU</td>\n",
       "      <td>TN22BT4664</td>\n",
       "      <td>736100.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>FAIR</td>\n",
       "      <td>Live : 29/03/2022</td>\n",
       "      <td>Expired : 31/03/2021</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>a9</td>\n",
       "      <td>AC000156811</td>\n",
       "      <td>CHINNAVELLAI  CHINNAVELLAI</td>\n",
       "      <td>ARUPKT908140010</td>\n",
       "      <td>Original RC</td>\n",
       "      <td>IMMOVABLE</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>AMW_2516HL_6X2CARGOTRUCK</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MKTCV1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2005</td>\n",
       "      <td>AMW</td>\n",
       "      <td>2516HL</td>\n",
       "      <td>6X2CARGOTRUCK</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AMW2516HL6X2CARGOTRUCKDIESEL</td>\n",
       "      <td>HAULAGE TRUCK</td>\n",
       "      <td>10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY</td>\n",
       "      <td>10</td>\n",
       "      <td>25000</td>\n",
       "      <td>231646</td>\n",
       "      <td>MADHYAPRADESH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1112310.000</td>\n",
       "      <td>40-50%</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>VALID</td>\n",
       "      <td>VALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ORIGINAL RC</td>\n",
       "      <td>MOVABLE</td>\n",
       "      <td>OEM</td>\n",
       "      <td>AMW_2516HL_6X2CARGOTRUCK</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MKTCV2</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2005</td>\n",
       "      <td>AMW</td>\n",
       "      <td>2516HL</td>\n",
       "      <td>6X2CARGOTRUCK</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AMW2516HL6X2CARGOTRUCKDIESEL</td>\n",
       "      <td>HAULAGE TRUCK</td>\n",
       "      <td>10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY</td>\n",
       "      <td>10</td>\n",
       "      <td>25000</td>\n",
       "      <td>243837</td>\n",
       "      <td>BIHAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1050260.000</td>\n",
       "      <td>40-50%</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>VALID</td>\n",
       "      <td>VALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ORIGINAL RC</td>\n",
       "      <td>MOVABLE</td>\n",
       "      <td>OEM</td>\n",
       "      <td>AMW_2516HL_6X2CARGOTRUCK</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MKTCV3</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>AMW</td>\n",
       "      <td>2516HL</td>\n",
       "      <td>6X2CARGOTRUCK</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AMW2516HL6X2CARGOTRUCKDIESEL</td>\n",
       "      <td>HAULAGE TRUCK</td>\n",
       "      <td>10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY</td>\n",
       "      <td>10</td>\n",
       "      <td>25000</td>\n",
       "      <td>243837</td>\n",
       "      <td>HARYANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1050260.000</td>\n",
       "      <td>40-50%</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>VALID</td>\n",
       "      <td>VALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ORIGINAL RC</td>\n",
       "      <td>MOVABLE</td>\n",
       "      <td>OEM</td>\n",
       "      <td>AMW_2516HL_6X2CARGOTRUCK</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UNIQUESERIALNO  SOLD_DATE  MAKE_YEAR Make_Clean Model_Clean  Variant_Clean  \\\n",
       "0   S20091800155 2020-11-26       2013        AMW      2516HL  6X2CARGOTRUCK   \n",
       "1   S21092900303 2021-09-11       2010        AMW      2516HL  6X2CARGOTRUCK   \n",
       "2         MKTCV1 2022-01-01       2005        AMW      2516HL  6X2CARGOTRUCK   \n",
       "3         MKTCV2 2021-01-01       2005        AMW      2516HL  6X2CARGOTRUCK   \n",
       "4         MKTCV3 2022-01-01       2006        AMW      2516HL  6X2CARGOTRUCK   \n",
       "\n",
       "  Fuel_Clean             mixmmvfuelcleaned       BodyType  \\\n",
       "0     DIESEL  AMW2516HL6X2CARGOTRUCKDIESEL  HAULAGE TRUCK   \n",
       "1     DIESEL  AMW2516HL6X2CARGOTRUCKDIESEL  HAULAGE TRUCK   \n",
       "2     DIESEL  AMW2516HL6X2CARGOTRUCKDIESEL  HAULAGE TRUCK   \n",
       "3     DIESEL  AMW2516HL6X2CARGOTRUCKDIESEL  HAULAGE TRUCK   \n",
       "4     DIESEL  AMW2516HL6X2CARGOTRUCKDIESEL  HAULAGE TRUCK   \n",
       "\n",
       "                                      SUBBODYTYPE  WHEELS  num_Weight  \\\n",
       "0  10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY      10       25000   \n",
       "1  10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY      10       25000   \n",
       "2  10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY      10       25000   \n",
       "3  10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY      10       25000   \n",
       "4  10 WHEELS / GVW 25000KG TO 28500KG /RIGID BODY      10       25000   \n",
       "\n",
       "   SOLD AMOUNT CV_State_Clean  VEHICLE NO  METER READING     UCR  \\\n",
       "0       445000        GUJARAT   GJ16Z6727     490620.000     20%   \n",
       "1       315000      TAMILNADU  TN22BT4664     736100.000     0.2   \n",
       "2       231646  MADHYAPRADESH         NaN    1112310.000  40-50%   \n",
       "3       243837          BIHAR         NaN    1050260.000  40-50%   \n",
       "4       243837        HARYANA         NaN    1050260.000  40-50%   \n",
       "\n",
       "  SHROTCOND_MAPPED              INSDT                   TAX  PERMIT_MAPPED  \\\n",
       "0             FAIR  Live : 28/02/2021  Expired : 30/09/2019  NOT AVAILABLE   \n",
       "1             FAIR  Live : 29/03/2022  Expired : 31/03/2021  NOT AVAILABLE   \n",
       "2             GOOD               LIVE                 VALID          VALID   \n",
       "3             GOOD               LIVE                 VALID          VALID   \n",
       "4             GOOD               LIVE                 VALID          VALID   \n",
       "\n",
       "  SELLERCORPORATENAME     SELLERID                   SELLERNAME  \\\n",
       "0                  a9  AP000337591  JAYESHBHAI  ZAVERBHAI PATEL   \n",
       "1                  a9  AC000156811   CHINNAVELLAI  CHINNAVELLAI   \n",
       "2                 NaN          NaN                          NaN   \n",
       "3                 NaN          NaN                          NaN   \n",
       "4                 NaN          NaN                          NaN   \n",
       "\n",
       "      KEYREFNUMBER INV_H_RC_STATUS_CLEANED_MAPPED VEHICLECONDITION  \\\n",
       "0  BHARUO608090001                    ORIGINAL RC          MOVABLE   \n",
       "1  ARUPKT908140010                    Original RC        IMMOVABLE   \n",
       "2              NaN                    ORIGINAL RC          MOVABLE   \n",
       "3              NaN                    ORIGINAL RC          MOVABLE   \n",
       "4              NaN                    ORIGINAL RC          MOVABLE   \n",
       "\n",
       "  SELLER SEGMENT                       MMV  Year_sell  Sell_Month  Sell_Day  \\\n",
       "0         RETAIL  AMW_2516HL_6X2CARGOTRUCK       2020          11        26   \n",
       "1      Insurance  AMW_2516HL_6X2CARGOTRUCK       2021           9        11   \n",
       "2            OEM  AMW_2516HL_6X2CARGOTRUCK       2022           1         1   \n",
       "3            OEM  AMW_2516HL_6X2CARGOTRUCK       2021           1         1   \n",
       "4            OEM  AMW_2516HL_6X2CARGOTRUCK       2022           1         1   \n",
       "\n",
       "   num_CV_Age  \n",
       "0           7  \n",
       "1          11  \n",
       "2          17  \n",
       "3          16  \n",
       "4          16  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_1[df_1[\"BodyType\"]=='TRACTOR TRAILER' ].value_counts\n",
    "\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2[['TAX_STATUS','TAX_DATE']] = df_2['TAX'].str.split(\":\",expand=True)\n",
    "\n",
    "df_2['TAX_STATUS']= df_2['TAX_STATUS'].str.lstrip()\n",
    "df_2['TAX_STATUS']= df_2['TAX_STATUS'].str.rstrip()\n",
    "\n",
    "df_2['TAX_STATUS']=df_2['TAX_STATUS'].str.upper()\n",
    "\n",
    "df_2['TAX_STATUS'].value_counts()\n",
    "\n",
    "TAX_STATUS={\n",
    "    \"LIFE TIME\":\"LIFE_TIME\",\n",
    "    \"NOT AVAILABLE\":\"NOT_AVAILABLE\",\n",
    "    \"PAID UPTO\":\"PAID_UPTO\",\n",
    "    \"EXPIRED\":\"EXPIRED\",\n",
    "    \"VALID UPTO\":\"VALID_UPTO\",\n",
    "    \"NOT APPLICABLE\":\"NOT_APPLICABLE\",\n",
    "    \"LIFE TAX\":\"LIFE_TAX\",\n",
    "    \"DATE IS NOT AVAILABLE\":\"DATE_NOT_AVAILABLE\"\n",
    "    }\n",
    "\n",
    "df_2['TAX_STATUS'].replace(TAX_STATUS, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VALID                 93128\n",
       "LIFE_TIME             78219\n",
       "PAID_UPTO             61708\n",
       "NOT_AVAILABLE         50203\n",
       "EXPIRED               46331\n",
       "VALID_UPTO             6408\n",
       "LIFETIME               2138\n",
       "NOT_APPLICABLE         1602\n",
       "PAIDUPTO               1583\n",
       "LIFE_TAX               1494\n",
       "NOTAVAILABLE            430\n",
       "VALIDUPTO               318\n",
       "DATE_NOT_AVAILABLE      105\n",
       "LIFETAX                  91\n",
       "NOTAPPLICABLE            34\n",
       "Name: TAX_STATUS, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['TAX_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNIQUESERIALNO', 'SOLD_DATE', 'MAKE_YEAR', 'Make_Clean', 'Model_Clean',\n",
       "       'Variant_Clean', 'Fuel_Clean', 'mixmmvfuelcleaned', 'BodyType',\n",
       "       'SUBBODYTYPE', 'WHEELS', 'num_Weight', 'SOLD AMOUNT', 'CV_State_Clean',\n",
       "       'VEHICLE NO', 'METER READING', 'UCR', 'SHROTCOND_MAPPED', 'INSDT',\n",
       "       'TAX', 'PERMIT_MAPPED', 'SELLERCORPORATENAME', 'SELLERID', 'SELLERNAME',\n",
       "       'KEYREFNUMBER', 'INV_H_RC_STATUS_CLEANED_MAPPED', 'VEHICLECONDITION',\n",
       "       'SELLER SEGMENT', 'MMV', 'Year_sell', 'Sell_Month', 'Sell_Day',\n",
       "       'num_CV_Age', 'TAX_STATUS', 'TAX_DATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-e1903405fdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'METER_READING_cleaned'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'METER READING'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\d.]+\"\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "df_2['METER_READING_cleaned'] = df_2['METER READING'].str.replace(r'[^\\d.]+\"\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['METER_READING_cleaned']=pd.to_numeric(df_2['METER_READING_cleaned'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['METER_READING_cleaned'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_reading_upper=df_2['METER_READING_cleaned'].mean()+3*df_2['METER_READING_cleaned'].std()\n",
    "meter_reading_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df_2[~(df_2['METER_READING_cleaned']>meter_reading_upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['METER_READING_cleaned'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_21=df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2[df_2.METER_READING_cleaned == df_2.METER_READING_cleaned.max()])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['METER_READING_cleaned'] = df_2['METER_READING_cleaned'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2['METER_READING_cleaned'] = df_2['METER_READING_cleaned'].replace([9281120,9231261,9111099,9006008,8817191,8164387,8040906,8038913,7774861,7748961,7674216,7627843], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['METER_READING_cleaned'].values[df_2['METER_READING_cleaned'] > 4000000] = 141557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['METER_READING_cleaned'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['WHEELS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['WHEELS'] = df_2['WHEELS'].replace({0:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['num_Weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['num_Weight'] = df_2['num_Weight'].replace({0:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['num_Weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['MMV']=df_2['Make_Clean']+df_2['Model_Clean']+df_2['Variant_Clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.isnull().sum()/len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_null = df_2.isnull().sum() / len(df_2)\n",
    "missing_features = pct_null[pct_null > 0.70].index\n",
    "# df.drop(missing_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1=df_2.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (8,8))        # Size of the figure\n",
    "sns.heatmap(inp1.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unseen_df = df_2.loc[(df_2['SOLD_DATE'] >= '2022-03-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unseen_for_model=Unseen_df[['MMV','Fuel_Clean','BodyType', 'MAKE_YEAR','Make_Clean','Model_Clean','Variant_Clean',\n",
    "       'SOLD AMOUNT', 'CV_State_Clean','SHROT COND_MAPPED','num_Weight','Year_sell',\n",
    "       'num_CV_Age','PERMIT_MAPPED','INV_H_CATEGORY_mapping','METER_READING_cleaned',\n",
    "           'INV_H_RC_STATUS_CLEANED_MAPPED','GP_PURPOSE_CLEANED','VEHICLECONDITION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=df_2.loc[(df_2['SOLD_DATE'] < '2022-03-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=mydata[['MMV','Fuel_Clean','BodyType', 'MAKE_YEAR','Make_Clean','Model_Clean','Variant_Clean',\n",
    "       'SOLD AMOUNT', 'CV_State_Clean','SHROT COND_MAPPED','num_Weight','Year_sell',\n",
    "       'num_CV_Age','PERMIT_MAPPED','INV_H_CATEGORY_mapping','METER_READING_cleaned',\n",
    "           'INV_H_RC_STATUS_CLEANED_MAPPED','GP_PURPOSE_CLEANED','VEHICLECONDITION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MMV','Fuel_Clean','BodyType', 'MAKE_YEAR','Make_Clean','Model_Clean','Variant_Clean',\n",
    "       'SOLD AMOUNT', 'CV_State_Clean','SHROT COND_MAPPED','num_Weight','Year_sell',\n",
    "       'num_CV_Age','PERMIT_MAPPED','INV_H_CATEGORY_mapping','METER_READING_cleaned',\n",
    "           'INV_H_RC_STATUS_CLEANED_MAPPED','GP_PURPOSE_CLEANED','VEHICLECONDITION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Enginerring\n",
    "df_2.reset_index(drop=True,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unseen_for_model.reset_index(drop=True,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_f=Model_data.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_f=['MMV', 'Fuel_Clean', 'BodyType',\n",
    "       'CV_State_Clean','SHROT COND_MAPPED', \n",
    "       'PERMIT_MAPPED', 'INV_H_CATEGORY_mapping',\n",
    "       'INV_H_RC_STATUS_CLEANED_MAPPED', 'GP_PURPOSE_CLEANED',\n",
    "       'VEHICLECONDITION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f=Model_data.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1=Model_data.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "\n",
    "\n",
    "for i,b in enumerate(list(inp1.columns)):\n",
    "    \n",
    "    i +=1\n",
    "    ax = fig.add_subplot(1,6,i)\n",
    "    sns.boxplot(inp1[b])\n",
    "\n",
    "    ax.set_title(b)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=Model_data.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,7))\n",
    " \n",
    "for i, col in enumerate(inp1):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  sns.distplot(inp1[col])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_cat=Model_data.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.loc[Model_data['MMV'].isin((Model_data['MMV'].value_counts()[Model_data['MMV'].value_counts(normalize=True) < 0.005]).index), 'MMV'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data[\"PERMIT_MAPPED\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['SHROT COND_MAPPED'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.loc[Model_data['SHROT COND_MAPPED'].isin((Model_data['SHROT COND_MAPPED'].value_counts()[Model_data['SHROT COND_MAPPED'].value_counts(normalize=True) < 0.015]).index), 'SHROT COND_MAPPED'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['SHROT COND_MAPPED'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['PERMIT_MAPPED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['BodyType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.loc[Model_data['BodyType'].isin((Model_data['BodyType'].value_counts()[Model_data['BodyType'].value_counts(normalize=True) <= 0.020]).index), 'BodyType'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['BodyType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['INV_H_RC_STATUS_CLEANED_MAPPED'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.loc[Model_data['INV_H_RC_STATUS_CLEANED_MAPPED'].isin((Model_data['INV_H_RC_STATUS_CLEANED_MAPPED'].value_counts()[Model_data['INV_H_RC_STATUS_CLEANED_MAPPED'].value_counts(normalize=True) <= 0.013]).index), 'INV_H_RC_STATUS_CLEANED_MAPPED'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['INV_H_RC_STATUS_CLEANED_MAPPED'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['CV_State_Clean'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['CV_State_Clean'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.loc[Model_data['CV_State_Clean'].isin((Model_data['CV_State_Clean'].value_counts()[Model_data['CV_State_Clean'].value_counts(normalize=True) <= 0.009]).index), 'CV_State_Clean'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.rename(columns={'CV_Age':'num_CV_Age'},inplace=True)\n",
    "Model_data.rename(columns={'METER_READING_cleaned':'num_METER_READING_cleaned'},inplace=True)\n",
    "Model_data.rename(columns={'SOLD AMOUNT':'num_SOLD_AMOUNT'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f=['WHEELS', 'num_Weight', 'num_SOLD AMOUNT', 'num_CV_Age','num_METER_READING_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features =  [col for col in Model_data if col.startswith('num_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import gaussian_kde\n",
    "#fig = plt.figure(figsize=(18,5))\n",
    "#\n",
    "#\n",
    "#for i,b in enumerate(list(Model_data[num_features].columns)):\n",
    "#    \n",
    "#    i +=1\n",
    "#    ax = fig.add_subplot(1,5,i)\n",
    "#    sns.boxplot(Model_data[num_features][b])\n",
    "#\n",
    "#    ax.set_title(b)\n",
    "#\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.tight_layout()\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_outlier_IQR(df):\n",
    "#    Q1=df.quantile(0.05)\n",
    "#    Q3=df.quantile(0.95)\n",
    "#    IQR=Q3-Q1\n",
    "#    df_final=df[~((df<(Q1-1.5*IQR)) | (df>(Q3+1.5*IQR)))]\n",
    "#    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data[num_features] = remove_outlier_IQR(Model_data[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the 0th moment \n",
    "print('0th moment is =',stats.moment(Model_data[num_features],moment=0))\n",
    "#finding the 1st moment \n",
    "print('1st moment is =',stats.moment(Model_data[num_features],moment=1))\n",
    "#finding the 2nd moment \n",
    "print('2nd moment is =',stats.moment(Model_data[num_features],moment=2))\n",
    "#finding the 3rd moment \n",
    "print('3rd moment is =',stats.moment(Model_data[num_features],moment=3))\n",
    "#finding the 4th moment \n",
    "print('4th moment is =',stats.moment(Model_data[num_features],moment=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import gaussian_kde\n",
    "#fig = plt.figure(figsize=(18,5))\n",
    "#\n",
    "#\n",
    "#for i,b in enumerate(list(Model_data[num_features].columns)):\n",
    "#    \n",
    "#    i +=1\n",
    "#    ax = fig.add_subplot(1,5,i)\n",
    "#    sns.boxplot(Model_data[num_features][b])\n",
    "#\n",
    "#    ax.set_title(b)\n",
    "#\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.tight_layout()\n",
    "#plt.legend()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.isnull().sum()/len(Model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install verstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from verstack import NaNImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = NaNImputer(fill_nans_in_pure_text = True)\n",
    "#Model_data = imputer.impute(Model_data)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Model_data.MMV.value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ pip install verstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.fillna(Model_data.select_dtypes(include='number').median().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.fillna(Model_data.select_dtypes(include='object').mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data.to_csv('Model_dataxx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_moment1=Model_data.groupby('MMV', as_index=False)['num_SOLD_AMOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_moment1=Model_data.groupby('MMV', as_index=False)['num_SOLD_AMOUNT'].mean().rename(columns = {'num_SOLD_AMOUNT':'Moment_1'})\n",
    "#Model_data_moment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Model_data_m1=Model_data.merge(Model_data_moment1,on='MMV',how='left')\n",
    "#Model_data_m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_moment2=Model_data_m1.groupby('MMV', as_index=False)['num_SOLD_AMOUNT'].var().rename(columns = {'num_SOLD_AMOUNT':'Moment_2'})\n",
    "#Model_data_moment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_m2=Model_data_m1.merge(Model_data_moment2,on='MMV',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_moment3=Model_data_m2.groupby('MMV', as_index=False)['num_SOLD_AMOUNT'].skew(axis = 0, skipna = True).rename(columns = {'num_SOLD_AMOUNT':'Moment_3'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_m3=Model_data_m2.merge(Model_data_moment3,on='MMV',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data_moment4=Model_data_m3.groupby('MMV', as_index=False)['num_SOLD_AMOUNT'].apply(pd.DataFrame.kurt).rename(columns = {'num_SOLD_AMOUNT':'Moment_4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data_moment4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_moment=Model_data_m3.merge(Model_data_moment4,on='MMV',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data=Model_moment.copy()\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data\n",
    "df_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(Model_data, df_inf, on='Year_sell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df['Inf_Pric'] = merged_df.apply(lambda row: row['num_SOLD_AMOUNT'] * (1 + 'Inf_rate'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Inf_rate'] = df['Inf_rate'].str.rstrip('%').astype(float) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['Year_sell'].agg(['min', 'max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data['MAKE_YEAR'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data['Inf_Pric'] = Model_data['num_SOLD_AMOUNT'] * df_inf.set_index['Inf_rate']\n",
    "# define a lambda function to multiply inflated price and sold amount\n",
    "#_inflated_sold = lambda row: row['Inf_rate'] * row['num_SOLD_AMOUNT']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the lambda function to each row to calculate inflated sold amount\n",
    "#merged_df['Inf_Pric'] = merged_df.apply(_inflated_sold, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_inflated_sold = lambda row: row['Inf_Pric'] + row['num_SOLD_AMOUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df['Inf_Pric@'] = merged_df.apply(_inflated_sold, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data_moment4=Model_data.groupby('MMV', as_index=False)['num_SOLD_AMOUNT']\n",
    "#profile = pp.ProfileReport(Model_data)\n",
    "#profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor as vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(Model_data.columns[:-1])):\n",
    "#    v=vif(np.matrix(Model_data[:-1]),i)\n",
    "#    print('Varince {}:{}'.format(Model_data[i],round(v,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data.merge(Model_data_moment1,on='MMV',how='left')\n",
    "#Model_data.merge(Model_data_moment2,on='MMV',how='left')\n",
    "#Model_data.merge(Model_data_moment3,on='MMV',how='left')\n",
    "#Model_data.merge(Model_data_moment4,on='MMV',how='left')\n",
    "#Model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_data = pd.get_dummies(Model_data, columns = ['MMV','Fuel_Clean', 'BodyType','MAKE_YEAR', 'Make_Clean', 'Model_Clean', 'Variant_Clean',\n",
    "       'CV_State_Clean','SHROT COND_MAPPED', \n",
    "       'PERMIT_MAPPED', 'INV_H_CATEGORY_mapping',\n",
    "       'INV_H_RC_STATUS_CLEANED_MAPPED', 'GP_PURPOSE_CLEANED',\n",
    "       'VEHICLECONDITION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data=one_hot_encoded_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=['num_Weight', 'num_CV_Age',\n",
    "       'num_METER_READING_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 = num_f.quantile(0.25)\n",
    "#Q3 = num_f.quantile(0.75)\n",
    "#IQR = Q3 - Q1\n",
    "#print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "Model_data[num_features]=scaler.fit_transform(Model_data[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data.drop(['Annual'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_data1=Model_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import stats\n",
    "#import numpy as np\n",
    "#z = np.abs(stats.zscore(model_data1))\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = 3\n",
    "#print(np.where(z > 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 = model_data1.quantile(0.25)\n",
    "#Q3 = model_data1.quantile(0.75)\n",
    "#IQR = Q3 - Q1\n",
    "#print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_data1 < (Q1 - 1.5 * IQR)) |(model_data1 > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_data.info()\n",
    "#Model_data=model_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Model_data.drop(['num_SOLD_AMOUNT'],axis=1)\n",
    "y=Model_data[['num_SOLD_AMOUNT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,\n",
    "                                                                    y,\n",
    "                                                                    test_size=0.25,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    random_state=0)\n",
    "print(y.shape[0])\n",
    "print(y_train.shape[0])\n",
    "print(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.1, gamma=0, learning_rate=0.005, max_delta_step=0.7,\n",
    "       max_depth=10, min_child_num_Weight=2, missing=1, n_estimators=850,\n",
    "       n_jobs=1, nthread=None, objective='reg:squarederror', random_state=707,\n",
    "       reg_alpha=10, reg_lambda=300, scale_pos_num_Weight=0.1, seed=42,\n",
    "       silent=True, subsample=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "#       colsample_bytree=0.1, gamma=0, learning_rate=0.005, max_delta_step=0.7,\n",
    "#       max_depth=10, min_child_num_Weight=2, missing=1, n_estimators=850,\n",
    "#       n_jobs=1, nthread=None, objective='reg:squarederror', random_state=707,\n",
    "#       reg_alpha=10, reg_lambda=300, scale_pos_num_Weight=0.1, seed=42,\n",
    "#       silent=True, subsample=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, early_stopping_rounds=900, eval_metric=[\"mape\",'error','logloss'],\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train, y_train)\n",
    "results = clf.evals_result()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(results[\"validation_0\"][\"mape\"], label=\"Training loss\")\n",
    "plt.plot(results[\"validation_1\"][\"mape\"], label=\"Test loss\")\n",
    "plt.axvline(21, color=\"gray\", label=\"Base\")\n",
    "plt.xlabel(\"Number of rounds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "#n_estimators = [100, 500]\n",
    "max_depth = [2, 3, 5, 8, 10, 12, 15]\n",
    "learning_rate=[0.001,0.01,0.05,0.1,0.15,0.20,0.30]\n",
    "min_child_num_Weight=[1,2,3,4,5,7]\n",
    "#'min_child_weight': np.arange(0.1, 10.1, 0.1)\n",
    "#gamma=[7,10]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_num_Weight':min_child_num_Weight,\n",
    "    #'min_child_weight': np.arange(0.1, 10.1, 0.1),\n",
    "    'booster':booster,\n",
    "    'base_score':base_score,\n",
    "    #'gamma':gamma\n",
    "    }#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 2-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=2,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42,\n",
    "            refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=1\n",
    "#kf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "#for train_index,test_index in kf.split(X,y):\n",
    "#     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "#     xtr,xvl = X.loc[train_index],X.loc[test_index]\n",
    "#     ytr,yvl = y[train_index],y[test_index]\n",
    "#     model = GridSearchCV(XGBClassifier() ,param_distributions=hyperparameter_grid, cv=10, scoring= 'f1',iid=True)\n",
    "#     model.fit(xtr, ytr)\n",
    "#     print (model.best_params_)\n",
    "#     pred=model.predict(xvl)\n",
    "#     print('accuracy_score',accuracy_score(yvl,pred))\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " random_cv.best_params_, random_cv.best_score_, random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=random_cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy=X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy['Predicted']=y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy['Actual']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files\\Graphviz\\bin.dot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = X_test_copy[X_test_copy[\"Actual\"] != X_test_copy[\"Predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy['Abs Error'] = abs(X_test_copy['Actual'] - X_test_copy['Predicted'])\n",
    "\n",
    "# Calculate the percentile rank of the absolute error within the test data set\n",
    "X_test_copy['Error Rank'] = X_test_copy['Abs Error'].rank(pct=True)\n",
    "\n",
    "# Select the top 5% of highly wrong predictions\n",
    "highly_wrong_predictions = X_test_copy[X_test_copy['Error Rank'] >= 0.95]\n",
    "\n",
    "# Print the highly wrong predictions\n",
    "#print(highly_wrong_predictions)\n",
    "highly_wrong_predictions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_wrong_predictions1 = highly_wrong_predictions[highly_wrong_predictions['MMV']=='other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy['Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE=abs((X_train_copy['Actual']-X_train_copy['Predicted'])/X_train_copy['Actual']).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig = plt.figure()\n",
    "sns.distplot((X_train_copy['Actual'] - X_train_copy['Predicted']), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  \n",
    "plt.xlabel('Errors', fontsize = 18)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=random_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_test=abs((X_test_copy['Actual']-X_test_copy['Predicted'])/X_test_copy['Actual']).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(X_train_copy['Actual'], X_train_copy['Predicted'], c='crimson')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "\n",
    "p1 = max(max(X_train_copy['Predicted']), max(X_train_copy['Actual']))\n",
    "p2 = min(min(X_train_copy['Predicted']), min(X_train_copy['Actual']))\n",
    "plt.plot([p1, p2], [p1, p2])\n",
    "plt.xlabel('Actual', fontsize=15)\n",
    "plt.ylabel('Predicted', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.set_context(\"notebook\")\n",
    "ax1 = sns.distplot(X_train_copy['Actual'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(X_train_copy['Predicted'], hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = max(max(X_train_copy['Predicted']), max(X_train_copy['Actual']))\n",
    "p2 = min(min(X_train_copy['Predicted']), min(X_train_copy['Actual']))\n",
    "#px.plot([p1, p2], [p1, p2])\n",
    "#px.xlabel('Actual', fontsize=15)\n",
    "#px.ylabel('Predicted', fontsize=15)\n",
    "#px.axis('equal')\n",
    "#px.show()\n",
    "#df = px.data.tips()\n",
    "fig = px.scatter(X_train_copy, x = \"Actual\", y = \"Predicted\")\n",
    "fig.add_traces(go.Scatter(x=[p1,p2], y=[p1,p2], name='Regression Fit'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=random_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = [round(value) for value in y_test_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# retrieve performance metrics\n",
    "results = clf.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Log Loss')\n",
    "plt.show()\n",
    "# plot classification error\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "#ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "#ax.legend()\n",
    "#plt.ylabel('Classification Error')\n",
    "#plt.title('XGBoost Classification Error')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy=X_test.copy()\n",
    "X_test_copy['Predicted']=y_test_pred\n",
    "X_test_copy['Actual']=y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy['Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = Model_data.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_test=abs((X_test_copy['Actual']-X_test_copy['Predicted'])/X_test_copy['Actual']).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.set_context(\"notebook\")\n",
    "ax1 = sns.distplot(X_test_copy['Actual'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(X_test_copy['Predicted'], hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig = plt.figure()\n",
    "sns.distplot((X_test_copy['Actual'] - X_test_copy['Predicted']), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  \n",
    "plt.xlabel('Errors', fontsize = 18)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "#_model_ = smf.ols(\"outcome ~ predictor\", data=Model_data).fit()\n",
    "\n",
    "# Train the XGBRegressor model\n",
    "#model = xgb.XGBRegressor()\n",
    "#model.fit(X_train, y_train)\n",
    "#\n",
    "# Plot the first tree of the model\n",
    "#plt.figure(figsize=(20, 20))\n",
    "#regressor.plot_tree(clf, num_trees=0)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# Train the XGBRegressor model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Plot the first tree of the model\n",
    "dot_data = plot_tree(model, num_trees=0, rankdir='LR')\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('tree_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary statistics\n",
    "#print(_model_.summary())\n",
    "\n",
    "# Make predictions\n",
    "#predictions = model.predict(Model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(X_test_copy['Actual'], X_test_copy['Predicted'], c='crimson')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "\n",
    "p1 = max(max(X_test_copy['Predicted']), max(X_test_copy['Actual']))\n",
    "p2 = min(min(X_test_copy['Predicted']), min(X_test_copy['Actual']))\n",
    "plt.plot([p1, p2], [p1, p2])\n",
    "plt.xlabel('Actual', fontsize=15)\n",
    "plt.ylabel('Predicted', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    early_stopping_rounds = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(early_stopping_rounds, train_metrics)\n",
    "    plt.plot(early_stopping_rounds, val_metrics)\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the data\n",
    "#df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Fit the model\n",
    "model = smf.ols(\"outcome ~ predictor\", data=Model_data).fit()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(model.summary())\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(Model_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
